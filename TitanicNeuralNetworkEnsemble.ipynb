{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "training_data = pd.read_csv(\"train.csv\")\n",
    "testing_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Store the unique identifier of each passenger in a separate dataframe for later use\n",
    "trainingIndex = pd.DataFrame()\n",
    "trainingIndex[\"PassengerId\"] = training_data[\"PassengerId\"]\n",
    "\n",
    "testingIndex = pd.DataFrame()\n",
    "testingIndex[\"PassengerId\"] = testing_data[\"PassengerId\"]\n",
    "\n",
    "# Extract target values\n",
    "trainingTargets = pd.DataFrame()\n",
    "trainingTargets[\"Survived\"] = training_data[\"Survived\"]\n",
    "\n",
    "# Remove columns containing information that is not strictly related to a passenger's survival\n",
    "columns_to_drop = [\"PassengerId\", \"Name\", \"Ticket\", \"Fare\", \"Embarked\", \"Survived\"]\n",
    "training_data = training_data.drop(columns=columns_to_drop, axis=1)\n",
    "testing_data = testing_data.drop(columns=list(set(columns_to_drop) - {\"Survived\"}), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ea513c2a913fc6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Find non numerical columns\n",
    "columns_to_encode = training_data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# One hot encode the 'Sex' column\n",
    "training_data = pd.get_dummies(training_data, columns=['Sex'])\n",
    "testing_data = pd.get_dummies(testing_data, columns=['Sex'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3863aedd26c9312"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert cabin numbers to simple cabin classes. E.g C58 --> C, A12 --> A\n",
    "def extract_first_char(value):\n",
    "    if pd.notna(value): \n",
    "        return value[0] \n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "training_data['Cabin'] = training_data['Cabin'].apply(lambda x: extract_first_char(x))\n",
    "testing_data['Cabin'] = testing_data['Cabin'].apply(lambda x: extract_first_char(x))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68b52189c788f944"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Columns to impute\n",
    "mean_imputation_columns = [\"Age\"]\n",
    "most_frequent_imputation_columns = [\"Cabin\"]\n",
    "\n",
    "# Instantiate the imputers\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "most_frequent_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Fit the imputer on the selected columns\n",
    "mean_imputer.fit(training_data[mean_imputation_columns])\n",
    "most_frequent_imputer.fit(training_data[most_frequent_imputation_columns])\n",
    "\n",
    "# Transform the selected columns\n",
    "training_data[mean_imputation_columns] = mean_imputer.transform(training_data[mean_imputation_columns])\n",
    "training_data[most_frequent_imputation_columns] = most_frequent_imputer.transform(training_data[most_frequent_imputation_columns])\n",
    "\n",
    "testing_data[mean_imputation_columns] = mean_imputer.transform(testing_data[mean_imputation_columns])\n",
    "testing_data[most_frequent_imputation_columns] = most_frequent_imputer.transform(testing_data[most_frequent_imputation_columns])\n",
    "\n",
    "# One hot encode the 'Cabin' column\n",
    "training_data = pd.get_dummies(training_data, columns=['Cabin'])\n",
    "testing_data = pd.get_dummies(testing_data, columns=['Cabin'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6e00d801dded411"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Scale age values to the 0-1 value range\n",
    "scaler = MinMaxScaler()\n",
    "training_data[\"Age\"] = scaler.fit_transform(training_data[[\"Age\"]])\n",
    "testing_data[\"Age\"] = scaler.transform(testing_data[[\"Age\"]])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74a1fcb199327328"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create and compile models to be used\n",
    "model = Sequential([\n",
    "    Dense(8, activation='relu', input_shape=(training_data.shape[1],)),\n",
    "    Dense(4, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(training_data.shape[1],)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model3 = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(training_data.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82f874f9321bdc52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the models\n",
    "training_data, validation_data, training_targets, validation_targets = train_test_split(training_data, trainingTargets, test_size=0.1, random_state=42)\n",
    "history = model.fit(training_data, training_targets, epochs=100, batch_size=32, validation_data=(validation_data, validation_targets),  verbose=1)\n",
    "history2 = model2.fit(training_data, training_targets, epochs=35, batch_size=32, validation_data=(validation_data, validation_targets),  verbose=1)\n",
    "history3 = model3.fit(training_data, training_targets, epochs=20, batch_size=32, validation_data=(validation_data, validation_targets),  verbose=1)\n",
    "\n",
    "# Plot training loss and accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4bce879f4f4848c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testing_data[\"Cabin_T\"] = 0\n",
    "\n",
    "predictions = model.predict(testing_data)\n",
    "predictions2 = model2.predict(testing_data)\n",
    "predictions3 = model3.predict(testing_data)\n",
    "\n",
    "binary_predictions = (predictions > 0.5).astype(int)\n",
    "binary_predictions2 = (predictions2 > 0.5).astype(int)\n",
    "binary_predictions3 = (predictions3 > 0.5).astype(int)\n",
    "\n",
    "final_predictions = []\n",
    "for i in range(len(predictions)):\n",
    "    if binary_predictions[i] + binary_predictions2[i] + binary_predictions3[i] > 1:\n",
    "        final_predictions.append(1)\n",
    "    else:\n",
    "        final_predictions.append(0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de775116ca7f9690"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filename = 'my_predictions.csv'\n",
    "\n",
    "predictions_list = list(final_predictions)\n",
    "index_list = testingIndex['PassengerId'].tolist()\n",
    "\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    \n",
    "    # Write header row\n",
    "    csvwriter.writerow([\"PassengerId\", \"Survived\"])\n",
    "    \n",
    "    # Write data rows\n",
    "    for index in range(418):\n",
    "        passenger_id = index_list[index]\n",
    "        prediction = predictions_list[index]\n",
    "        csvwriter.writerow([passenger_id, prediction])\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9394b603dcba3d5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
